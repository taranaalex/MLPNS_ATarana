{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taranaalex/MLPNS_ATarana/blob/main/transformers/assess_TS_classification_w_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timeseries classification with a Transformer model\n",
        "\n",
        "**Author:** [Theodoros Ntakouris](https://github.com/ntakouris)<br>\n",
        "**Date created:** 2021/06/25<br>\n",
        "**Last modified:** 2021/08/05<br>\n",
        "**Description:** This notebook demonstrates how to do timeseries classification using a Transformer model."
      ],
      "metadata": {
        "id": "ZQ-nRNLhognE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "THIS KERAS EXAMPLE OF APPLICATION OF TRANSFORMERS TO TIME SERIES ANALYSIS IS **WRONG**\n",
        "\n",
        "My student Willow Fox Fortino found that out... "
      ],
      "metadata": {
        "id": "X9L2K8IfPS5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This is the Transformer architecture from\n",
        "[Attention Is All You Need](https://arxiv.org/abs/1706.03762),\n",
        "applied to timeseries instead of natural language.\n",
        "\n",
        "This example requires TensorFlow 2.4 or higher.\n",
        "\n",
        "## Load the dataset\n",
        "\n",
        "We are going to use the same dataset and preprocessing as the\n",
        "[TimeSeries Classification from Scratch](https://keras.io/examples/timeseries/timeseries_classification_from_scratch)\n",
        "example."
      ],
      "metadata": {
        "id": "2-8RslF7ognH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf7pcMVatnVR",
        "outputId": "4a39eed8-97c6-4697-93e3-86b3cc9f7e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/MLPNS2023/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB7sWeyptvTZ",
        "outputId": "e0b5c1cd-4149-42ad-d033-aa051ce95ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLPNS2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "XMBJszHaognI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1: \n",
        "\n",
        "the author provide no data exploration. That is not acceptable. Explore the data"
      ],
      "metadata": {
        "id": "Ddlb5cxOZ-xc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
        "where `sequence length` is the number of time steps and `features` is each input\n",
        "timeseries.\n",
        "\n",
        "You can replace your classification RNN layers with this one: the\n",
        "inputs are fully compatible!"
      ],
      "metadata": {
        "id": "8mHX4SxaognJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "outputs": [],
      "metadata": {
        "id": "krGMC9mDognJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We include residual connections, layer normalization, and dropout.\n",
        "The resulting layer can be stacked multiple times.\n",
        "\n",
        "The projection layers are implemented through `keras.layers.Conv1D`."
      ],
      "metadata": {
        "id": "8vqf9PsfognJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "vZyK2X9PognJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main part of our model is now complete. We can stack multiple of those\n",
        "`transformer_encoder` blocks and we can also proceed to add the final\n",
        "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
        "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
        "our model down to a vector of features for each data point in the current\n",
        "batch. A common way to achieve this is to use a pooling layer. For\n",
        "this example, a `GlobalAveragePooling1D` layer is sufficient."
      ],
      "metadata": {
        "id": "rItYDH_LognK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "XvxrXqWKognK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate"
      ],
      "metadata": {
        "id": "wXT9pqcuognL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "\"\"\"\n",
        "create a model with :\n",
        "4 multiattention heads each size 256, \n",
        "4 transformer blocks\n",
        "4 neurons in the convolutional layers\n",
        "128 neurons in the feed forward layers\n",
        "dropout 40% on the transformer layers\n",
        "dropout 25% on the feed forward layers\n",
        "\n",
        "compile it with a sparse_categorical_crossentropy,\n",
        "choose the kearas adam optimizer with a learning rate of 1e-4\n",
        "monitor the sparse_categorical_accuracy metric\n",
        "\"\"\"\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "model = keras.models.load_model('transformer_h4_model.h5')\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, \n",
        "                                           restore_best_weights=True)]\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 500, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization_32 (LayerN  (None, 500, 1)      2           ['input_5[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_16 (Multi  (None, 500, 1)      7169        ['layer_normalization_32[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_16[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_31 (TFOpL  (None, 500, 1)      0           ['dropout_34[0][0]',             \n",
            " ambda)                                                           'input_5[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_33 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_31[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)           (None, 500, 4)       0           ['conv1d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 500, 1)       5           ['dropout_35[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_32 (TFOpL  (None, 500, 1)      0           ['conv1d_31[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_31[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_34 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_32[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_17 (Multi  (None, 500, 1)      7169        ['layer_normalization_34[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_36 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_17[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_33 (TFOpL  (None, 500, 1)      0           ['dropout_36[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_32[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_35 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_33[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 500, 4)       0           ['conv1d_32[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 500, 1)       5           ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_34 (TFOpL  (None, 500, 1)      0           ['conv1d_33[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_33[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_36 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_34[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_18 (Multi  (None, 500, 1)      7169        ['layer_normalization_36[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_18[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_35 (TFOpL  (None, 500, 1)      0           ['dropout_38[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_34[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_37 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_35[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_34 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_39 (Dropout)           (None, 500, 4)       0           ['conv1d_34[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 500, 1)       5           ['dropout_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_36 (TFOpL  (None, 500, 1)      0           ['conv1d_35[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_35[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_38 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_36[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_19 (Multi  (None, 500, 1)      7169        ['layer_normalization_38[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_19[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_37 (TFOpL  (None, 500, 1)      0           ['dropout_40[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_36[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_39 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_37[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_41 (Dropout)           (None, 500, 4)       0           ['conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 500, 1)       5           ['dropout_41[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_38 (TFOpL  (None, 500, 1)      0           ['conv1d_37[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_37[0][0]']\n",
            "                                                                                                  \n",
            " global_average_pooling1d_3 (Gl  (None, 500)         0           ['tf.__operators__.add_38[0][0]']\n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          64128       ['global_average_pooling1d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_42 (Dropout)           (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 2)            258         ['dropout_42[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 93,130\n",
            "Trainable params: 93,130\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "Zin3w41vognL",
        "outputId": "2415521d-9c45-49b1-ac1c-d6cd1116b22d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/transformer_h4_history', \"rb\") as file_pi:\n",
        "    history_4h = pickle.load(file_pi)\n",
        "   "
      ],
      "metadata": {
        "id": "DfYi3lZTWIHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab as plt\n",
        "print accuracy and loss\n",
        "\n",
        "plot the history .... what do you see?"
      ],
      "metadata": {
        "id": "u6Ibqh6wENkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "Official version: In about 110-120 epochs (25s each on Colab), the model reaches a training\n",
        "accuracy of ~0.95, validation accuracy of ~84 and a testing\n",
        "accuracy of ~85, without hyperparameter tuning. And that is for a model\n",
        "with less than 100k parameters. Of course, parameter count and accuracy could be\n",
        "improved by a hyperparameter search and a more sophisticated learning rate\n",
        "schedule, or a different optimizer.\n",
        "\n",
        "You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/timeseries_transformer_classification) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/timeseries_transformer_classification).\n",
        "\n",
        "**Reality** these transformer blocks are not doing anything! \n",
        "- there is no positional encoding\n",
        "- the time series are 1D and its not clear that the performance holds going from multivariate (tockenized) to univariate\n"
      ],
      "metadata": {
        "id": "HV47sNxGognL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "\"\"\"\n",
        "create another model with :\n",
        "1 multiattention head size 256, \n",
        "0 transformer blocks\n",
        "4 neurons in the convolutional layers\n",
        "128 neurons in the feed forward layers\n",
        "dropout 40% on the transformer layers\n",
        "dropout 25% on the feed forward layers\n",
        "\n",
        "compile it with a sparse_categorical_crossentropy,\n",
        "choose the kearas adam optimizer with a learning rate of 1e-4\n",
        "monitor the sparse_categorical_accuracy metric\n",
        "\"\"\"\n",
        "\n",
        "model.summary()\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "g6ReU0K01Mxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print accuracy and loss\n",
        "\n",
        "plot the history .... what do you see?"
      ],
      "metadata": {
        "id": "BcJd-Ql-1jAY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22pKCTzpXGq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}